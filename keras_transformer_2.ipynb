{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "904cbf74-0976-4e14-8533-5e74250b32e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.6.4\n",
      "JAX version: 0.3.13\n",
      "Interactive? True\n",
      "368\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout, BatchNormalization\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # GPU 0だけを使用するように設定\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "        # 必要に応じてメモリ成長を許可\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e:\n",
    "        # プログラムの実行時にデバイスが設定されているとエラーが発生するので注意\n",
    "        print(e)\n",
    "\n",
    "# Environment Configuration\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "def setup_environment():\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    print(f\"JAX version: {jax.__version__}\")\n",
    "\n",
    "    def is_interactive():\n",
    "        return 'runtime' in get_ipython().config.IPKernelApp.connection_file\n",
    "\n",
    "    print('Interactive?', is_interactive())\n",
    "\n",
    "    SEED = 42\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)\n",
    "    return is_interactive\n",
    "\n",
    "is_interactive = setup_environment()\n",
    "\n",
    "# Paths and Data Loading\n",
    "DATA = \"../data\"\n",
    "DATA_TFREC = \"../data\"\n",
    "\n",
    "def load_data(sample_path, tfrec_path):\n",
    "    sample = pl.read_csv(sample_path, n_rows=1)\n",
    "    TARGETS = sample.select(pl.exclude('sample_id')).columns\n",
    "    print(len(TARGETS))\n",
    "\n",
    "    def _parse_function(example_proto):\n",
    "        feature_description = {\n",
    "            'x': tf.io.FixedLenFeature([556], tf.float32),\n",
    "            'targets': tf.io.FixedLenFeature([368], tf.float32)\n",
    "        }\n",
    "        e = tf.io.parse_single_example(example_proto, feature_description)\n",
    "        return e['x'], e['targets']\n",
    "\n",
    "    train_files = [os.path.join(tfrec_path, \"train_%.3d.tfrec\" % i) for i in range(100)]\n",
    "    valid_files = [os.path.join(tfrec_path, \"train_%.3d.tfrec\" % i) for i in range(100, 101)]\n",
    "\n",
    "    return TARGETS, train_files, valid_files, _parse_function\n",
    "\n",
    "TARGETS, train_files, valid_files, _parse_function = load_data(\n",
    "    os.path.join(DATA, \"sample_submission.csv\"),\n",
    "    DATA_TFREC\n",
    ")\n",
    "\n",
    "# Data Pipeline\n",
    "BATCH_SIZE = 2048\n",
    "train_options = tf.data.Options()\n",
    "train_options.experimental_deterministic = True\n",
    "\n",
    "def create_dataset(files, batch_size, parse_function, train=True):\n",
    "    ds = (\n",
    "        tf.data.Dataset.from_tensor_slices(files)\n",
    "        .with_options(train_options)\n",
    "        .shuffle(100)\n",
    "        .interleave(\n",
    "            lambda file: tf.data.TFRecordDataset(file).map(parse_function, num_parallel_calls=tf.data.AUTOTUNE),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE,\n",
    "            cycle_length=10,\n",
    "            block_length=1000,\n",
    "            deterministic=True\n",
    "        )\n",
    "        .shuffle(4 * batch_size if train else 1)\n",
    "        .batch(batch_size)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    return ds\n",
    "\n",
    "ds_train = create_dataset(train_files, BATCH_SIZE, _parse_function, train=True)\n",
    "ds_valid = create_dataset(valid_files, BATCH_SIZE, _parse_function, train=False)\n",
    "\n",
    "# Normalization\n",
    "def normalize_data(ds_train, ds_valid):\n",
    "    norm_x = keras.layers.Normalization()\n",
    "    norm_x.adapt(ds_train.map(lambda x, y: x).take(20 if is_interactive else 1000))\n",
    "\n",
    "    plt.scatter(\n",
    "        norm_x.mean.numpy().squeeze(),\n",
    "        np.sqrt(norm_x.variance.numpy().squeeze()),\n",
    "        marker=\".\",\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    norm_y = keras.layers.Normalization()\n",
    "    norm_y.adapt(ds_train.map(lambda x, y: y).take(20 if is_interactive else 1000))\n",
    "\n",
    "    mean_y = norm_y.mean.numpy()\n",
    "    stdd_y = np.maximum(1e-10, np.sqrt(norm_y.variance.numpy()))\n",
    "\n",
    "    plt.scatter(\n",
    "        mean_y.squeeze(),\n",
    "        stdd_y.squeeze(),\n",
    "        marker=\".\",\n",
    "        alpha=0.5\n",
    "    )\n",
    "    plt.xscale('log')\n",
    "    plt.yscale('log')\n",
    "\n",
    "    min_y = np.min(np.stack([np.min(yb, 0) for _, yb in ds_train.take(20 if is_interactive else 1000)], 0), 0, keepdims=True)\n",
    "    max_y = np.max(np.stack([np.max(yb, 0) for _, yb in ds_train.take(20 if is_interactive else 1000)], 0), 0, keepdims=True)\n",
    "\n",
    "    return norm_x, norm_y, mean_y, stdd_y\n",
    "\n",
    "norm_x, norm_y, mean_y, stdd_y = normalize_data(ds_train, ds_valid)\n",
    "\n",
    "# Model Definition\n",
    "class ClippedR2Score(keras.metrics.Metric):\n",
    "    def __init__(self, name='r2_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.base_metric = keras.metrics.MeanSquaredError()\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        self.base_metric.update_state(y_true, y_pred, sample_weight)\n",
    "\n",
    "    def result(self):\n",
    "        r2_score = 1 - self.base_metric.result()\n",
    "        return tf.reduce_mean(tf.clip_by_value(r2_score, 0.0, 1.0))\n",
    "\n",
    "    def reset_states(self):\n",
    "        self.base_metric.reset_states()\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df494cb4-71d3-4be4-b416-578fb314c883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 556)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "normalization_2 (Normalization) (None, 556)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem (Slici (None, 360)          0           normalization_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_1 (Sli (None, 180)          0           normalization_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_2 (Sli (None, 16)           0           normalization_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape (TFOpLambda)         (None, 6, 60)        0           tf.__operators__.getitem[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_1 (TFOpLambda)       (None, 3, 60)        0           tf.__operators__.getitem_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.reshape_2 (TFOpLambda)       (None, 1, 16)        0           tf.__operators__.getitem_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose (TFOpLam (None, 60, 6)        0           tf.reshape[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_1 (TFOpL (None, 60, 3)        0           tf.reshape_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.tile (TFOpLambda)            (None, 60, 16)       0           tf.reshape_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat (TFOpLambda)          (None, 60, 25)       0           tf.compat.v1.transpose[0][0]     \n",
      "                                                                 tf.compat.v1.transpose_1[0][0]   \n",
      "                                                                 tf.tile[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "transformer_encoder (Transforme (None, 60, 14)       1197326     tf.concat[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_3 (Sli (None, 60, 6)        0           transformer_encoder[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf.compat.v1.transpose_2 (TFOpL (None, 6, 60)        0           tf.__operators__.getitem_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.getitem_4 (Sli (None, 60, 8)        0           transformer_encoder[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 360)          0           tf.compat.v1.transpose_2[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf.math.reduce_mean (TFOpLambda (None, 8)            0           tf.__operators__.getitem_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "tf.concat_1 (TFOpLambda)        (None, 368)          0           flatten[0][0]                    \n",
      "                                                                 tf.math.reduce_mean[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 1,197,326\n",
      "Trainable params: 1,197,070\n",
      "Non-trainable params: 256\n",
      "__________________________________________________________________________________________________\n",
      "<MapDataset shapes: ((None, 556), (None, 368)), types: (tf.float32, tf.float32)>\n",
      "<MapDataset shapes: ((None, 556), (None, 368)), types: (tf.float32, tf.float32)>\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-03 14:14:25.821644: W tensorflow/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-07-03 14:14:25.821687: W tensorflow/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at /usr/local/cuda-11.0/bin/ptxas\n",
      "2024-07-03 14:14:25.821815: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] Unimplemented: /usr/local/cuda-11.0/bin/ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4883/Unknown - 1892s 385ms/step - loss: 0.3695 - r2_score: 0.6305"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/metrics.py:257: UserWarning: Metric ClippedR2Score implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  'consistency.' % (self.__class__.__name__,))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4883/4883 [==============================] - 1899s 387ms/step - loss: 0.3695 - r2_score: 0.6305 - val_loss: 0.2844 - val_r2_score: 0.7156\n",
      "Epoch 2/50\n",
      "4883/4883 [==============================] - 1883s 385ms/step - loss: 0.3074 - r2_score: 0.6926 - val_loss: 0.2613 - val_r2_score: 0.7387\n",
      "Epoch 3/50\n",
      "4883/4883 [==============================] - 1886s 386ms/step - loss: 0.2928 - r2_score: 0.7072 - val_loss: 0.2544 - val_r2_score: 0.7456\n",
      "Epoch 4/50\n",
      "4883/4883 [==============================] - 1886s 386ms/step - loss: 0.2856 - r2_score: 0.7144 - val_loss: 0.2515 - val_r2_score: 0.7485\n",
      "Epoch 5/50\n",
      "4883/4883 [==============================] - 1888s 387ms/step - loss: 0.2803 - r2_score: 0.7197 - val_loss: 0.2446 - val_r2_score: 0.7554\n",
      "Epoch 6/50\n",
      "4883/4883 [==============================] - 1884s 386ms/step - loss: 0.2757 - r2_score: 0.7243 - val_loss: 0.2406 - val_r2_score: 0.7594\n",
      "Epoch 7/50\n",
      "4883/4883 [==============================] - 1885s 386ms/step - loss: 0.2733 - r2_score: 0.7267 - val_loss: 0.2493 - val_r2_score: 0.7507\n",
      "Epoch 8/50\n",
      "4883/4883 [==============================] - 1885s 386ms/step - loss: 0.2704 - r2_score: 0.7296 - val_loss: 0.2464 - val_r2_score: 0.7536\n",
      "Epoch 9/50\n",
      "4883/4883 [==============================] - 1883s 386ms/step - loss: 0.2703 - r2_score: 0.7297 - val_loss: 0.2343 - val_r2_score: 0.7657\n",
      "Epoch 10/50\n",
      "4883/4883 [==============================] - 1885s 386ms/step - loss: 0.2663 - r2_score: 0.7337 - val_loss: 0.2402 - val_r2_score: 0.7598\n",
      "Epoch 11/50\n",
      "4883/4883 [==============================] - 1884s 386ms/step - loss: 0.2665 - r2_score: 0.7335 - val_loss: 0.2335 - val_r2_score: 0.7665\n",
      "Epoch 12/50\n",
      "4883/4883 [==============================] - 1884s 386ms/step - loss: 0.2652 - r2_score: 0.7348 - val_loss: 0.2325 - val_r2_score: 0.7675\n",
      "Epoch 13/50\n",
      "4883/4883 [==============================] - 1883s 386ms/step - loss: 0.2634 - r2_score: 0.7366 - val_loss: 0.2413 - val_r2_score: 0.7587\n",
      "Epoch 14/50\n",
      "4883/4883 [==============================] - 1884s 386ms/step - loss: 0.2607 - r2_score: 0.7393 - val_loss: 0.2314 - val_r2_score: 0.7686\n",
      "Epoch 15/50\n",
      "4883/4883 [==============================] - 1884s 386ms/step - loss: 0.2579 - r2_score: 0.7421 - val_loss: 0.2302 - val_r2_score: 0.7698\n",
      "Epoch 16/50\n",
      "4883/4883 [==============================] - 1886s 386ms/step - loss: 0.2580 - r2_score: 0.7420 - val_loss: 0.2313 - val_r2_score: 0.7687\n",
      "Epoch 17/50\n",
      "4883/4883 [==============================] - 1884s 386ms/step - loss: 0.2546 - r2_score: 0.7454 - val_loss: 0.2257 - val_r2_score: 0.7743\n",
      "Epoch 18/50\n",
      "4883/4883 [==============================] - 1883s 386ms/step - loss: 0.2531 - r2_score: 0.7469 - val_loss: 0.2258 - val_r2_score: 0.7742\n",
      "Epoch 19/50\n",
      "4883/4883 [==============================] - 1887s 386ms/step - loss: 0.2514 - r2_score: 0.7486 - val_loss: 0.2242 - val_r2_score: 0.7758\n",
      "Epoch 20/50\n",
      "4883/4883 [==============================] - 1882s 385ms/step - loss: 0.2525 - r2_score: 0.7475 - val_loss: 0.2258 - val_r2_score: 0.7742\n",
      "Epoch 21/50\n",
      "4883/4883 [==============================] - 1886s 386ms/step - loss: 0.2504 - r2_score: 0.7496 - val_loss: 0.2226 - val_r2_score: 0.7774\n",
      "Epoch 22/50\n",
      "4883/4883 [==============================] - 1878s 384ms/step - loss: 0.2479 - r2_score: 0.7521 - val_loss: 0.2215 - val_r2_score: 0.7785\n",
      "Epoch 23/50\n",
      "4883/4883 [==============================] - 1876s 384ms/step - loss: 0.2493 - r2_score: 0.7507 - val_loss: 0.2220 - val_r2_score: 0.7780\n",
      "Epoch 24/50\n",
      "4883/4883 [==============================] - 1878s 385ms/step - loss: 0.2454 - r2_score: 0.7546 - val_loss: 0.2196 - val_r2_score: 0.7804\n",
      "Epoch 25/50\n",
      "4883/4883 [==============================] - 1878s 385ms/step - loss: 0.2445 - r2_score: 0.7555 - val_loss: 0.2213 - val_r2_score: 0.7787\n",
      "Epoch 26/50\n",
      "4883/4883 [==============================] - 1877s 384ms/step - loss: 0.2427 - r2_score: 0.7573 - val_loss: 0.2238 - val_r2_score: 0.7762\n",
      "Epoch 27/50\n",
      "4883/4883 [==============================] - 1877s 384ms/step - loss: 0.2407 - r2_score: 0.7593 - val_loss: 0.2195 - val_r2_score: 0.7805\n",
      "Epoch 28/50\n",
      "4883/4883 [==============================] - 1876s 384ms/step - loss: 0.2399 - r2_score: 0.7601 - val_loss: 0.2182 - val_r2_score: 0.7818\n",
      "Epoch 29/50\n",
      "4883/4883 [==============================] - 1876s 384ms/step - loss: 0.2385 - r2_score: 0.7615 - val_loss: 0.2171 - val_r2_score: 0.7829\n",
      "Epoch 30/50\n",
      "4883/4883 [==============================] - 1904s 390ms/step - loss: 0.2371 - r2_score: 0.7629 - val_loss: 0.2179 - val_r2_score: 0.7821\n",
      "Epoch 31/50\n",
      "4883/4883 [==============================] - 1900s 389ms/step - loss: 0.2352 - r2_score: 0.7648 - val_loss: 0.2143 - val_r2_score: 0.7857\n",
      "Epoch 32/50\n",
      "4883/4883 [==============================] - 1880s 385ms/step - loss: 0.2345 - r2_score: 0.7655 - val_loss: 0.2154 - val_r2_score: 0.7846\n",
      "Epoch 33/50\n",
      "4883/4883 [==============================] - 1878s 385ms/step - loss: 0.2334 - r2_score: 0.7666 - val_loss: 0.2150 - val_r2_score: 0.7850\n",
      "Epoch 34/50\n",
      "4883/4883 [==============================] - 1894s 388ms/step - loss: 0.2319 - r2_score: 0.7681 - val_loss: 0.2142 - val_r2_score: 0.7858\n",
      "Epoch 35/50\n",
      "4883/4883 [==============================] - 1981s 406ms/step - loss: 0.2308 - r2_score: 0.7692 - val_loss: 0.2129 - val_r2_score: 0.7871\n",
      "Epoch 36/50\n",
      "4883/4883 [==============================] - 1877s 384ms/step - loss: 0.2299 - r2_score: 0.7701 - val_loss: 0.2130 - val_r2_score: 0.7870\n",
      "Epoch 37/50\n",
      "4883/4883 [==============================] - 1876s 384ms/step - loss: 0.2290 - r2_score: 0.7710 - val_loss: 0.2131 - val_r2_score: 0.7869\n",
      "Epoch 38/50\n",
      "4883/4883 [==============================] - 1876s 384ms/step - loss: 0.2281 - r2_score: 0.7719 - val_loss: 0.2153 - val_r2_score: 0.7847\n",
      "Epoch 39/50\n",
      "4883/4883 [==============================] - 1877s 384ms/step - loss: 0.2272 - r2_score: 0.7728 - val_loss: 0.2110 - val_r2_score: 0.7890\n",
      "Epoch 40/50\n",
      "4883/4883 [==============================] - 1875s 384ms/step - loss: 0.2265 - r2_score: 0.7735 - val_loss: 0.2112 - val_r2_score: 0.7888\n",
      "Epoch 41/50\n",
      "1605/4883 [========>.....................] - ETA: 20:57 - loss: 0.2212 - r2_score: 0.7788"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4883/4883 [==============================] - 1982s 406ms/step - loss: 0.2259 - r2_score: 0.7741 - val_loss: 0.2109 - val_r2_score: 0.7891\n",
      "Epoch 42/50\n",
      "4883/4883 [==============================] - 1932s 396ms/step - loss: 0.2251 - r2_score: 0.7749 - val_loss: 0.2102 - val_r2_score: 0.7898\n",
      "Epoch 43/50\n",
      "4883/4883 [==============================] - 1912s 391ms/step - loss: 0.2247 - r2_score: 0.7753 - val_loss: 0.2099 - val_r2_score: 0.7901\n",
      "Epoch 44/50\n",
      "4883/4883 [==============================] - 1876s 384ms/step - loss: 0.2243 - r2_score: 0.7757 - val_loss: 0.2098 - val_r2_score: 0.7902\n",
      "Epoch 45/50\n",
      "4883/4883 [==============================] - 1998s 409ms/step - loss: 0.2237 - r2_score: 0.7763 - val_loss: 0.2107 - val_r2_score: 0.7893\n",
      "Epoch 46/50\n",
      "4883/4883 [==============================] - 1898s 389ms/step - loss: 0.2235 - r2_score: 0.7765 - val_loss: 0.2102 - val_r2_score: 0.7898\n",
      "Epoch 47/50\n",
      "4883/4883 [==============================] - 1876s 384ms/step - loss: 0.2233 - r2_score: 0.7767 - val_loss: 0.2096 - val_r2_score: 0.7904\n",
      "Epoch 48/50\n",
      "4883/4883 [==============================] - 1885s 386ms/step - loss: 0.2231 - r2_score: 0.7769 - val_loss: 0.2105 - val_r2_score: 0.7895\n",
      "Epoch 49/50\n",
      "4883/4883 [==============================] - 1893s 388ms/step - loss: 0.2229 - r2_score: 0.7771 - val_loss: 0.2082 - val_r2_score: 0.7918\n",
      "Epoch 50/50\n",
      "4883/4883 [==============================] - 1889s 387ms/step - loss: 0.2228 - r2_score: 0.7772 - val_loss: 0.2097 - val_r2_score: 0.7903\n"
     ]
    }
   ],
   "source": [
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, d_model, dropout_rate, max_len=5000, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        \n",
    "        pos = tf.range(max_len, dtype=tf.float32)[:, tf.newaxis]\n",
    "        i = tf.range(d_model, dtype=tf.float32)[tf.newaxis, :]\n",
    "\n",
    "        angle_rads = self.get_angles(pos, i)\n",
    "        \n",
    "        # apply sin to even indices in the array; 2i\n",
    "        angle_rads_sin = tf.math.sin(angle_rads[:, 0::2])\n",
    "        \n",
    "        # apply cos to odd indices in the array; 2i+1\n",
    "        angle_rads_cos = tf.math.cos(angle_rads[:, 1::2])\n",
    "        \n",
    "        # concatenate sin and cos parts\n",
    "        angle_rads = tf.concat([angle_rads_sin, angle_rads_cos], axis=-1)\n",
    "        \n",
    "        pos_encoding = angle_rads[tf.newaxis, ...]\n",
    "\n",
    "        self.pos_encoding = tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def get_angles(self, pos, i):\n",
    "        angle_rates = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(self.d_model, tf.float32))\n",
    "        return pos * angle_rates\n",
    "\n",
    "    def call(self, x):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = x + self.pos_encoding[:, :seq_len, :]\n",
    "        return self.dropout(x)\n",
    "    \n",
    "class TransformerEncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout_rate, **kwargs):\n",
    "        super(TransformerEncoderLayer, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout_rate = dropout_rate\n",
    "\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=nhead, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(dim_feedforward, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training):\n",
    "        attn_output = self.mha(x, x, x)\n",
    "        \n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "        \n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(TransformerEncoderLayer, self).get_config()\n",
    "        config = {\n",
    "            'd_model': self.d_model,\n",
    "            'nhead': self.nhead,\n",
    "            'dim_feedforward': self.dim_feedforward,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        }\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, nhead, dim_feedforward, dropout_rate, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.num_layers = num_layers\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.dim_feedforward = dim_feedforward\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        self.batchnorm1 = keras.layers.BatchNormalization()\n",
    "        self.batchnorm2 = keras.layers.BatchNormalization()\n",
    "        self.input_linear = Dense(d_model)\n",
    "        self.pos_encoding = PositionalEncoding(d_model, dropout_rate)\n",
    "        self.enc_layers = [TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout_rate) for _ in range(num_layers)]\n",
    "        self.dropout = Dropout(dropout_rate)\n",
    "        self.conv1d = keras.layers.Conv1D(14, 1, padding='same')  # Move Conv1D definition here\n",
    "\n",
    "    def call(self, x, training):\n",
    "        x = self.input_linear(x)\n",
    "        x = self.batchnorm1(x)\n",
    "        \n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for enc_layer in self.enc_layers:\n",
    "            x = enc_layer(x, training=training)\n",
    "            \n",
    "        x = self.conv1d(x)  # Use self.conv1d here\n",
    "        return x\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(TransformerEncoder, self).get_config()\n",
    "        config = {\n",
    "            'num_layers': self.num_layers,\n",
    "            'd_model': self.d_model,\n",
    "            'nhead': self.nhead,\n",
    "            'dim_feedforward': self.dim_feedforward,\n",
    "            'dropout_rate': self.dropout_rate,\n",
    "        }\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def build_model(input_shape, norm_x, output_shape, d_model, nhead, num_encoder_layers, dim_feedforward, dropout_rate, learning_rate, steps_per_epoch, epochs):\n",
    "         \n",
    "    def x_to_seq(x):\n",
    "        x_seq0 = tf.transpose(tf.reshape(x[:, 0:60 * 6], (-1, 6, 60)), (0, 2, 1))\n",
    "        x_seq1 = tf.transpose(tf.reshape(x[:, 60 * 6 + 16:60 * 9 + 16], (-1, 3, 60)), (0, 2, 1))\n",
    "        x_flat = tf.reshape(x[:, 60 * 6:60 * 6 + 16], (-1, 1, 16))\n",
    "        x_flat = tf.tile(x_flat, [1, 60, 1])\n",
    "        return tf.concat([x_seq0, x_seq1, x_flat], axis=-1)\n",
    "    \n",
    "    transformer_encoder = TransformerEncoder(\n",
    "        num_encoder_layers,\n",
    "        d_model,\n",
    "        nhead,\n",
    "        dim_feedforward,\n",
    "        dropout_rate,\n",
    "    )\n",
    "\n",
    "    lr_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=learning_rate,\n",
    "        decay_steps=(epochs - 1 - 2) * steps_per_epoch,\n",
    "        alpha=0.1\n",
    "    )\n",
    "    \n",
    "    inputs = tf.keras.layers.Input(shape=input_shape)\n",
    "    x = tf.keras.layers.Normalization(mean=norm_x.mean.numpy(), variance=norm_x.variance.numpy())(inputs)\n",
    "    x = x_to_seq(x)\n",
    "    p_all = transformer_encoder(x)\n",
    "\n",
    "    p_seq = p_all[:, :, :6]\n",
    "    p_seq = tf.transpose(p_seq, (0, 2, 1))\n",
    "    p_seq = keras.layers.Flatten()(p_seq)\n",
    "\n",
    "    p_flat = tf.reduce_mean(p_all[:, :, 6:6 + 8], axis=1)\n",
    "\n",
    "    P = tf.concat([p_seq, p_flat], axis=1)\n",
    "    \n",
    "    model = Model(inputs, P)\n",
    "    \n",
    "\n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=lr_scheduler),\n",
    "        metrics=[ClippedR2Score()]\n",
    "    )\n",
    "    \n",
    "    model.build(input_shape=(None, input_shape))\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_model(model, train_data, val_data, save_path, epochs):\n",
    "    # ModelCheckpoint コールバックを作成\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=save_path,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_format='keras'  # Keras形式で保存\n",
    "    )\n",
    "\n",
    "    # モデルをトレーニング\n",
    "    history = model.fit(\n",
    "        train_data,\n",
    "        validation_data=val_data,\n",
    "        epochs=epochs,\n",
    "        callbacks=[checkpoint]\n",
    "    )\n",
    "\n",
    "    return history\n",
    "\n",
    "# パラメータの設定\n",
    "input_shape = (556)  # 例\n",
    "output_shape = (BATCH_SIZE, 368)  # 例\n",
    "\n",
    "# 変更可能なパラメータ\n",
    "d_model = 64\n",
    "nhead = 8\n",
    "num_encoder_layers = 6\n",
    "dim_feedforward = 512\n",
    "dropout_rate = 0\n",
    "learning_rate = 1e-3\n",
    "steps_per_epoch = int(np.ceil(len(train_files) * 100_000 / BATCH_SIZE))\n",
    "epochs = 50\n",
    "\"\"\"\n",
    "d_model = 128\n",
    "nhead = 3\n",
    "num_encoder_layers = 1\n",
    "dim_feedforward = 512\n",
    "dropout_rate = 0.1\n",
    "learning_rate = 0.0001\n",
    "steps_per_epoch = 1000\n",
    "epochs = 50\n",
    "\"\"\"\n",
    "save_path = \"model_transformer.keras\"\n",
    "\n",
    "# モデルの構築\n",
    "model = build_model(input_shape, norm_x, output_shape, d_model, nhead, num_encoder_layers, dim_feedforward, dropout_rate, learning_rate, steps_per_epoch, epochs)\n",
    "\n",
    "ds_train_target_normalized = ds_train.map(lambda x, y: (x, (y - mean_y) / stdd_y))\n",
    "ds_valid_target_normalized = ds_valid.map(lambda x, y: (x, (y - mean_y) / stdd_y))\n",
    "print(ds_train_target_normalized)\n",
    "print(ds_valid_target_normalized)\n",
    "\n",
    "# 前回保存したモデルをロード\n",
    "model_path = 'model_transformer_relearn.keras'\n",
    "custom_objects = {'ClippedR2Score': ClippedR2Score, 'PositionalEncoding': PositionalEncoding, 'TransformerEncoder': TransformerEncoder, 'TransformerEncoderLayer': TransformerEncoderLayer}\n",
    "model = keras.models.load_model(model_path, custom_objects=custom_objects)\n",
    "\n",
    "# トレーニングを再開\n",
    "history = train_model(model, ds_train_target_normalized, ds_valid_target_normalized, 'model_transformer_relearn.keras', epochs)\n",
    "# # モデルのトレーニング\n",
    "# history = train_model(model, train_data=ds_train_target_normalized, val_data=ds_valid_target_normalized, save_path=save_path, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9a9b4c-c534-4ec0-806a-65d93bf09529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['loss'], color='tab:blue')\n",
    "    plt.plot(history.history['val_loss'], color='tab:red')\n",
    "    plt.yscale('log')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history)\n",
    "\n",
    "y_valid = np.concatenate([yb for _, yb in ds_valid])\n",
    "p_valid = model.predict(ds_valid, batch_size=BATCH_SIZE) * stdd_y + mean_y\n",
    "\n",
    "scores_valid = np.array([metrics.r2_score(y_valid[:, i], p_valid[:, i]) for i in range(len(TARGETS))])\n",
    "plt.plot(scores_valid.clip(-1, 1))\n",
    "plt.show()\n",
    "\n",
    "mask = scores_valid <= 1e-3\n",
    "print(f\"Number of under-performing targets: {sum(mask)}\")\n",
    "print(f\"Clipped score: {scores_valid.clip(0, 1).mean()}\")\n",
    "\n",
    "del y_valid, p_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3876e82-a04a-44a0-86a8-5e4ee76f5626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ce052-efba-44a4-9e6e-ade71542fda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092ea2a-1425-46e8-80e3-730a074edb8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd692b3-0268-4eaa-b920-1d0fca5d1fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883cfc10-5aab-49c9-9257-80a3d23bbf4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
